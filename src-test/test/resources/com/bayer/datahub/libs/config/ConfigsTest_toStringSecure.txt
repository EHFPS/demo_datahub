Base configs (excluding producer and consumer):
    bq.stream.format=json
    client.error.strategy=SKIP_ALL_CLIENTS
    client.type=producer_db_delta
    consumer.base.guarantee=at_least_once
    consumer.base.poll.timeout.ms=50000
    consumer.es.connection.address=http://localhost:9200
    consumer.es.connection.password=the_password
    consumer.es.connection.truststore.password=the_keystore_password
    consumer.es.connection.truststore.path=c:/files/elastic-stack-ca.p12
    consumer.es.connection.username=the_username
    consumer.es.consumer.guarantee=AT_LEAST_ONCE
    consumer.es.consumer.poll.timeout.ms=60000
    consumer.es.format.type=JSON
    consumer.es.index.name=the_index
    consumer.file.binary.header.name=filename
    consumer.file.binary.output.dir=c:/Temp/binary
    consumer.file.file.format=avro
    consumer.file.file.path=c:/Temp/FileWriterTest/out.csv
    consumer.file.format.csv.charset=Windows-1251
    consumer.file.format.csv.record.delimiter=CRLF
    consumer.file.format.csv.value.delimiter=:
    consumer.file.retry.max.number=5
    consumer.file.retry.wait.time.ms=5000
    consumer.gcs.format.avro.object.name=the_avro_object_name
    consumer.gcs.format.binary.header.name=the_binary_header_name
    consumer.gcs.format.csv.charset=Windows-8
    consumer.gcs.format.csv.object.name=the_csv_object_name
    consumer.gcs.format.csv.record.delimiter=CRLF
    consumer.gcs.format.csv.value.delimiter=;
    consumer.gcs.format.type=BINARY
    consumer.gcs.gcs.bucket.name=the_bucket
    consumer.gcs.gcs.key.file=/the/key/file.json
    consumer.gcs.gcs.project.id=the_project_id
    consumer.gcs.gcs.proxy.host=the_gcs_proxy_host
    consumer.gcs.gcs.proxy.password=the_gcs_proxy_password
    consumer.gcs.gcs.proxy.port=6666
    consumer.gcs.gcs.proxy.user=the_gcs_proxy_user
    consumer.gcs.guarantee=AT_LEAST_ONCE
    consumer.gcs.output.dir=the_out_dir
    consumer.gcs.poll.timeout.ms=50000
    consumer.gcs.retry.max.number=8
    consumer.gcs.retry.wait.time.ms=8000
    consumer.gcs.upload.empty.files=false
    consumer.s3.aws.auth.basic.access.key=<hidden_not_empty>
    consumer.s3.aws.auth.basic.secret.key=<hidden_not_empty>
    consumer.s3.aws.auth.role.arn=the-arn
    consumer.s3.aws.auth.role.session=<hidden_not_empty>
    consumer.s3.aws.auth.type=BASIC
    consumer.s3.aws.bucket.name=s3-consumer
    consumer.s3.aws.region=eu-central-2
    consumer.s3.aws.service.endpoint=https://s3.eu-central-1.amazonaws.com
    consumer.s3.format.avro.s3.key.name=the_folder/the_file.avro
    consumer.s3.format.binary.header.name=filename1
    consumer.s3.format.csv.charset=Windows-1251
    consumer.s3.format.csv.record.delimiter=CRLF
    consumer.s3.format.csv.s3.key.name=the_folder/the_file.csv
    consumer.s3.format.csv.value.delimiter=;
    consumer.s3.format.type=avro
    consumer.s3.output.dir=c:/Temp
    consumer.s3.retry.max.number=6
    consumer.s3.retry.wait.time.ms=7000
    consumer.s3.upload.empty.files=false
    consumer.splunk.hec.auth.token=
    consumer.splunk.hec.indexer.ack=
    consumer.splunk.hec.keystore.location=
    consumer.splunk.hec.keystore.password=<empty>
    consumer.splunk.hec.override.host=
    consumer.splunk.hec.override.index=
    consumer.splunk.hec.override.source=
    consumer.splunk.hec.override.sourceType=
    consumer.splunk.hec.peers=
    consumer.splunk.hec.raw.endpoint=
    consumer.splunk.hec.raw.lineBreaker=
    consumer.splunk.hec.ssl=
    consumer.splunk.hec.verify.ssl=
    db.fetch=500
    db.host=by0q9s.de.bayer.cnb
    db.name=APS11R2B.LEV.DE.BAYER.CNB
    db.password=<hidden_not_empty>
    db.port=1522
    db.primary.key=PK
    db.schema=THE_DB_SCHEMA
    db.service.name=data
    db.table=V_BCK_MD_RL_PL_ACTVE_SUBSTANCE
    db.type=Oracle
    db.upsert=true
    db.username=<hidden_not_empty>
    gcs.file.prefix=prefix
    gcs.load.option=none
    google.application.credentials=/path/to/key.json
    google.bigquery.dataset=the-dataset
    google.bigquery.table=the-table
    google.project.id=project-id
    google.service.account.email=
    google.storage.bucket.name=the-bucket
    google.storage.folder.name=the-folder
    kafka.common.schema.registry.url=http://sr.awseuc1.tst.edh.cnb:8081
    kafka.common.topic=the-topic
    kafka.consumer.exit.on.finish=true
    kafka.consumer.include.metadata=false
    kafka.consumer.key.deserializer=avro
    kafka.consumer.key.field.name=kafka_key
    kafka.consumer.offset=-1
    kafka.consumer.offset.field.name=kafka_offset
    kafka.consumer.partition=-1
    kafka.consumer.partition.field.name=kafka_partition
    kafka.consumer.timestamp.field.name=kafka_created_ts
    kafka.consumer.value.deserializer=string
    kafka.producer.key.serializer=avro
    kafka.producer.value.serializer=string
    notification.kafka.allowed.statistics.types.by.comma=INTERMEDIATE,FINAL
    notification.kafka.bootstrap.servers=kafka-server:9093
    notification.kafka.key.password=<hidden_not_empty>
    notification.kafka.keystore.location=c:/dir/keystore
    notification.kafka.keystore.password=<hidden_not_empty>
    notification.kafka.topic=kafka-notification-topic
    notification.kafka.truststore.location=c:/dir/truststore
    notification.kafka.truststore.password=<hidden_not_empty>
    producer.csv.charset=Windows-1251
    producer.csv.file.batch.size=10000
    producer.csv.file.format=CSV
    producer.csv.file.path=c:/path/to/file/csv
    producer.csv.header=header1
    producer.csv.record.delimiter=LF
    producer.csv.value.delimiter=:
    producer.db.delta.column=CREATED
    producer.db.delta.max.override='2020-01-01 00:00:00'
    producer.db.delta.min.override='2019-01-01 00:00:00'
    producer.db.delta.poll.interval=3600
    producer.db.delta.query=SELECT * FROM THE_SCHEMA.THE_TABLE
    producer.db.delta.select.interval=1d
    producer.db.delta.type=TIMESTAMP
    producer.db.plain.metadata.column.order=
    producer.db.plain.metadata.date=
    producer.db.plain.metadata.format.date=yyyy-MM-dd
    producer.db.plain.metadata.record.key=the_producer_key
    producer.db.plain.metadata.topic=
    producer.db.plain.query=SELECT * FROM MYEVG_PLAIN.V_BCK_MD_RL_PL_ACTVE_SUBSTANCE
    producer.db.plain.range.column=date
    producer.db.plain.range.enable=false
    producer.db.plain.range.max='12 Feb 2020'
    producer.db.plain.range.min='11 Feb 2020'
    producer.sharedoc.base.url=https://sharedoc.com/api
    producer.sharedoc.chunk.size.bytes=1000000
    producer.sharedoc.http.timeout.seconds=1000
    producer.sharedoc.mode=metadata
    producer.sharedoc.parallelism=5
    producer.sharedoc.password=<hidden_not_empty>
    producer.sharedoc.query=select * from sd_document
    producer.sharedoc.repository=test-repo
    producer.sharedoc.username=<hidden_not_empty>
    statistics.intermediate.period.sec=60
